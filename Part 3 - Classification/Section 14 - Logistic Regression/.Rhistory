setwd("C:/Users/Administrator/Desktop/Machine_Learning_AZ/Part 4 - Clustering/Section 24 - K-Means Clustering")
dataset=read.csv('Mall_Customers.csv')
X=dataset[3:5]
X=dataset[4:5]
set.seed(100)
wcss=vector()
for(i in 1:10){
wcss[i]=sum(kmeans(X,i)$withinss)
}
plot(1:10,wcss,type='b',xlab='No. of clusters',ylab = 'Wcss')
set.seed(6)
wcss=vector()
for(i in 1:10){
wcss[i]=sum(kmeans(X,i)$withinss)
}
plot(1:10,wcss,type='b',xlab='No. of clusters',ylab = 'Wcss')
set.seed(60)
wcss=vector()
for(i in 1:10){
wcss[i]=sum(kmeans(X,i)$withinss)
}
plot(1:10,wcss,type='b',xlab='No. of clusters',ylab = 'Wcss')
set.seed(100)
wcss=vector()
for(i in 1:10){
wcss[i]=sum(kmeans(X,i)$withinss)
}
plot(1:10,wcss,type='b',xlab='No. of clusters',ylab = 'Wcss')
library("cluster", lib.loc="C:/Program Files/R/R-3.4.4/library")
#applying k means with 6 clusters
set.seed(100)
kmeans<-kmeans(X,6,iter.max = 300,nstart = 10)
clusplot(x,kmeans.cluster)
# visualizing
clusplot(X,kmeans.cluster)
kmeans
# visualizing
clusplot(X,kmeans$cluster)
# visualizing
clusplot(X,kmeans$cluster,lines = 0,shade = TRUE,color=TRUE,labels = 2)
#applying k means with 6 clusters
set.seed(29)
kmeans<-kmeans(X,5,iter.max = 300,nstart = 10)
# visualizing
clusplot(X,kmeans$cluster,lines = 0,shade = TRUE,color=TRUE,labels = 2)
# visualizing
clusplot(X,kmeans$cluster,lines = 0,shade = TRUE,color=TRUE,labels = 2,plotchar = FALSE,span = TRUE)
setwd("C:/Users/Administrator/Desktop/Machine_Learning_AZ/Part 4 - Clustering/Section 25 - Hierarchical Clustering")
library(cluster)
dataset=read.csv('Mall_Customers.csv')
X=dataset[4:5]
# dendrogram
dendrogram=hclust(dist(X,method = 'euclidean'),method = 'ward.D')
plot(dendrogram, main = paste('Dendrogram'),xlab = 'Customers',ylab = 'Euclidean Distance')
hc=hclust(dist(X,method = 'euclidean'),method = 'ward.D')
y_hc=cutree(hc,k=5)
y_hc
library(cluster)
clusplot(X,y_hc)
clusplot(X,y_hc,lines = 0,shade = TRUE,color = TRUE,plotchar = FALSE,span = TRUE)
setwd("C:/Users/Administrator/Desktop/Machine_Learning_AZ/Part 3 - Classification/Section 14 - Logistic Regression")
dataset=read.csv('Social_Network_Ads.csv')
X=dataset[3,4]
y=dataset[5]
dataset=read.csv('Social_Network_Ads.csv')
library(caTools)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv('Social_Network_Ads.csv')
library(caTools)
set.seed(100)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
set.seed(123)
dataset=read.csv('Social_Network_Ads.csv')
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3,4,5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
classifier=glm(Purchased ~ ., )
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3,4,5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3,4,5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3,4,5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3,4,5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3:5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
classifier=glm(Purchased ~ ., )
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3:5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
training_set[1:2]=scale(training_set[1:2])
training_set[1:2]=scale(training_set[1:2])
test_set[1:2]=scale(test_set[1:2])
training_set=subset(dataset,split==TRUE)
training_set[1:2]=scale(training_set[1:2])
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3:5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
training_set[1:2]=scale(training_set[1:2])
test_set[1:2]=scale(test_set[1:2])
prob_pred=predict(classifier,type='response',newdata=test_set[-3])
classifier=glm(Purchased ~ ., family=binomial,data = training_set)
prob_pred=predict(classifier,type='response',newdata=test_set[-3])
test_set=subset(dataset,split==FALSE)
clear
clr()
cls
cls()
shell('cls')
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3:5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.8)
# train test split
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
#feature scaling
training_set[1:2]=scale(training_set[1:2])
test_set[1:2]=scale(test_set[1:2])
classifier=glm(Purchased ~ ., family=binomial,data = training_set)
prob_pred=predict(classifier,type='response',newdata=test_set[-3])
prob_pred
y_pred=ifelse(prob_pred>=0.5,1,0)
y_pred
cm=table(test_set[,3],y_pred)
cm
install.packages('ElemStatLearn')
library(ElemStatLearn)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','Estimated Salary')
View(grid_set)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','Estimated Salary')
prob_pred=predict(classifier,type='response',newdata=grid_set)
y_grid=ifelse(prob_pred>=0.5,1,0)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
View(training_set)
library(ElemStatLearn)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
prob_pred=predict(classifier,type='response',newdata=grid_set)
y_grid=ifelse(prob_pred>=0.5,1,0)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
grid_set=expand.grid(X1,X2)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
prob_pred=predict(classifier,type='response',newdata=grid_set)
y_grid=ifelse(prob_pred>=0.5,1,0)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
prob_pred=predict(classifier,type='response',newdata=grid_set)
y_grid=ifelse(prob_pred>=0.5,1,0)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid=1,'springgreen3','tomato'))
points(set,pch=21,bg=ifelse(set[-3]=1,'green4','red3'))
library(ElemStatLearn)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
prob_pred=predict(classifier,type='response',newdata=grid_set)
y_grid=ifelse(prob_pred>=0.5,1,0)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'springgreen3','tomato'))
points(set,pch=21,bg=ifelse(set[-3]==1,'green4','red3'))
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
prob_pred=predict(classifier,type='response',newdata=grid_set)
y_grid=ifelse(prob_pred>=0.5,1,0)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'blue','tomato'))
points(set,pch=21,bg=ifelse(set[-3]==1,'green4','red3'))
prob_pred=predict(classifier,type='response',newdata=grid_set)
prob_pred
y_grid=ifelse(prob_pred>=0.5,1,0)
y_grid
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'blue','tomato'))
points(set,pch=21,bg=ifelse(set[-3]==1,'green4','red3'))
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'springgreen3','tomato'))
points(set,pch=21,bg=ifelse(set[-3]==1,'blue','red3'))
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'springgreen3','tomato'))
points(set,pch=21,col=ifelse(set[-3]==1,'blue','red3'))
source('~/.active-rstudio-document', echo=TRUE)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'springgreen3','tomato'))
points(set,pch=21,bg=ifelse(set[3]==1,'green4','red3'))
library("class", lib.loc="C:/Program Files/R/R-3.4.4/library")
classifier=knn(training_set,test_set,k=5)
classifier=knn(training_set[-3],test_set[-3],cl=training_set[3],k=5)
classifier=knn(train=training_set[-3],test=test_set[-3],cl=training_set[3],k=5)
classifier=knn(train=training_set[-3],test=test_set[-3],cl=training_set[,3],k=5)
y_pred=predict(classifier,type='response',newdata=test_set[-3])
y_pred=knn(train=training_set[-3],test=test_set[-3],cl=training_set[,3],k=5)
cm=table(test_set[,3],y_pred)
cm
y_grid=y_pred=knn(train=training_set[-3],test=grid_set,cl=training_set[,3],k=5)
library(ElemStatLearn)
set=training_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'springgreen3','tomato'))
points(set,pch=21,bg=ifelse(set[3]==1,'green4','red3'))
library(ElemStatLearn)
set=test_set
X1=seq(min(set[1]) - 1,max(set[1]) + 1,by=0.01)
X2=seq(min(set[2]) - 1,max(set[2]) + 1,by=0.01)
grid_set=expand.grid(X1,X2)
colnames(grid_set)=c('Age','EstimatedSalary')
y_grid=y_pred=knn(train=training_set[-3],test=grid_set,cl=training_set[,3],k=5)
plot(set[-3],xlim=range(X1),ylim=range(X2))
contour(X1,X2,matrix(as.numeric(y_grid),length(X1),length(X2)),add = TRUE)
points(grid_set,pch='.',col=ifelse(y_grid==1,'springgreen3','tomato'))
points(set,pch=21,bg=ifelse(set[3]==1,'green4','red3'))
